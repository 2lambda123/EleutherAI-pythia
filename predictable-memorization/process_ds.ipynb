{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# add parent directory to path\n",
    "import os, sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.mmap_dataset import MMapIndexedDataset\n",
    "import dask\n",
    "import dask.array as da\n",
    "from transformers import GPTNeoXForCausalLM, AutoTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "from dask.diagnostics import ProgressBar\n",
    "from dask.distributed import Lock\n",
    "from tqdm import tqdm\n",
    "from dask.diagnostics import ProgressBar\n",
    "from numpy.lib.stride_tricks import sliding_window_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_jobqueue import SLURMCluster\n",
    "\n",
    "cluster = SLURMCluster(cores=4,\n",
    "                       processes=2,\n",
    "                       memory=\"32GB\",\n",
    "                       walltime=\"48:00:00\",\n",
    "                       # project=\"fiete\",\n",
    "                       queue=\"normal\")\n",
    "cluster.scale(jobs=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b92748e158654a568451834ceee85c61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-OutputArea-output\">\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\">\n",
       "    </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px; margin-top: 0px;\">SLURMCluster</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">3999ba4b</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard:</strong> <a href=\"http://172.16.20.84:8787/status\" target=\"_blank\">http://172.16.20.84:8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Workers:</strong> 0\n",
       "                </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total threads:</strong> 0\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total memory:</strong> 0 B\n",
       "                </td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "\n",
       "        <details>\n",
       "            <summary style=\"margin-bottom: 20px;\">\n",
       "                <h3 style=\"display: inline;\">Scheduler Info</h3>\n",
       "            </summary>\n",
       "\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-9ede7b24-8c02-409f-9887-d75b749f96fd</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tcp://172.16.20.84:34505\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"http://172.16.20.84:8787/status\" target=\"_blank\">http://172.16.20.84:8787/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> Just now\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 0 B\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "\n",
       "        </details>\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "SLURMCluster(3999ba4b, 'tcp://172.16.20.84:34505', workers=0, threads=0, memory=0 B)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    reading sizes...\n",
      "    reading pointers...\n",
      "    reading document index...\n",
      "    creating numpy buffer of mmap...\n",
      "    creating memory view of numpy buffer...\n"
     ]
    }
   ],
   "source": [
    "dataset = MMapIndexedDataset('/om/user/sunnyd/data/datasets--EleutherAI--pile-standard-pythia-preshuffled-merged/document', skip_warmup = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11904/11904 [00:00<00:00, 84209.51it/s]\n"
     ]
    }
   ],
   "source": [
    "indices = np.load('0-1-43-idx.npy')\n",
    "emergent = []\n",
    "for idx in tqdm(indices):\n",
    "    emergent.append(dataset[int(idx)][:64])\n",
    "emergent = da.from_array(np.stack(emergent, axis=0), chunks=(100, 64))\n",
    "da.to_npy_stack(\n",
    "        'matching_data/',\n",
    "        emergent,\n",
    "        axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dask.delayed\n",
    "def load_chunk(path, ptr, total_size, dtype):\n",
    "    bin_buffer_mmap = np.memmap(path, mode=\"r\", order=\"C\")\n",
    "    bin_buffer = memoryview(bin_buffer_mmap)\n",
    "    data = np.frombuffer(bin_buffer, \n",
    "                         dtype=dtype, \n",
    "                         count=total_size, \n",
    "                         offset=ptr).reshape(-1, 2049)\n",
    "    return data\n",
    "    \n",
    "\n",
    "def mmap_dask_array(blocksize=1000, offset=0, max=50000):\n",
    "    load = dask.delayed(load_chunk)\n",
    "    chunks = []\n",
    "    max_idx = min(max, len(dataset))\n",
    "    for index in tqdm(range(offset, max_idx, blocksize)):\n",
    "        chunk_size = min(blocksize, max_idx - index)\n",
    "        path = '/om/user/sunnyd/data/datasets--EleutherAI--pile-standard-pythia-preshuffled-merged/document.bin'\n",
    "        ptr = dataset._index._pointers[index]\n",
    "        dtype = dataset._index.dtype\n",
    "        count = np.sum(dataset._index._sizes[index:index+chunk_size])\n",
    "        # Truncate the last chunk if necessary\n",
    "        chunk = dask.array.from_delayed(\n",
    "            load(path, ptr, count, dtype),\n",
    "            shape=(chunk_size, 2049),\n",
    "            dtype=dataset[0].dtype\n",
    "        )\n",
    "        chunks.append(chunk)\n",
    "    return da.concatenate(chunks, axis=0)\n",
    "\n",
    "def match(a, b):\n",
    "    # matches = np.empty([a.shape[0], b.shape[0]], dtype=bool)\n",
    "    # matches.fill(False)\n",
    "    # # return np.dot(a,b.T).reshape(1, 1, 1, 1)\n",
    "    # for i in range(b.shape[1] - a.shape[1]):\n",
    "    #     matches = np.logical_or(matches,\n",
    "    #                             np.max(np.abs(np.expand_dims(a, axis=1) - b[:, i:i+a.shape[1]]), axis=-1) == 0)\n",
    "    # return np.expand_dims(np.expand_dims(matches, -1), -1)\n",
    "    return np.expand_dims(np.expand_dims(\n",
    "        np.logical_or.reduce(np.max(np.abs(sliding_window_view(b, (100, 64)).squeeze() - a.reshape(-1, 1, 1, 64)), axis=-1) == 0, axis=1),\n",
    "        -1), -1)\n",
    "\n",
    "\n",
    "emergent = da.from_npy_stack('matching_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17837"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emergent.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping matches/0-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 6134.07it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 5415.30it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7381.33it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7923.07it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 8023.55it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7984.08it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 5296.60it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7501.51it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7781.53it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7612.07it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7910.81it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7513.87it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7791.00it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7450.85it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7517.56it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7741.79it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7778.07it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 6707.01it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7232.04it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7990.25it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7784.27it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7799.83it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7716.29it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7849.58it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7700.61it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7401.01it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7659.93it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 6327.16it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7833.42it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7785.00it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 5407.74it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7781.21it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7441.53it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7719.76it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:01<00:00, 1128.59it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 8164.00it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7992.39it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 6155.99it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7729.94it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7558.06it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 8109.71it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:01<00:00, 1172.90it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 8294.62it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 6487.75it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7509.29it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:01<00:00, 1133.80it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 8000.08it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7536.86it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7770.58it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7461.95it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 5550.68it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7756.26it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 5561.41it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7495.77it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7494.99it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7752.65it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7551.13it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 8072.60it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7602.24it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7944.48it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7139.95it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7763.95it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 6546.72it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7706.28it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 8015.27it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7831.06it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 8143.32it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7496.47it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7916.25it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7355.98it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 8057.42it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 6760.30it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7856.52it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7736.88it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7747.39it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 8043.97it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 6768.98it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7557.58it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7914.73it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 6919.96it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7678.03it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7792.24it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7838.78it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7468.32it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7413.40it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7423.82it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7917.64it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7808.35it/s]\n",
      "/tmp/ipykernel_3357493/4098411358.py:15: PerformanceWarning: Increasing number of chunks by factor of 20\n",
      "  da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# with ProgressBar():\n",
    "#     res = da.blockwise(match, 'ijab', emergent, 'ia', x[:2000], 'jb', dtype=int, \n",
    "#                        adjust_chunks={'a': 1, 'b': 1}).squeeze().compute()\n",
    "job_size = 200000\n",
    "job_size_emergent = 2000\n",
    "for j in range(emergent.shape[0] // job_size_emergent):\n",
    "    for i in range(len(dataset) // job_size): \n",
    "        res_path = f\"matches/{i}-{j}\"\n",
    "        if os.path.exists(res_path):\n",
    "            print(\"skipping \"+ res_path)\n",
    "            continue\n",
    "        x = mmap_dask_array(100, i * job_size, (i+1) * job_size)\n",
    "        da.to_npy_stack(\n",
    "                res_path,\n",
    "                da.blockwise(match, 'ijab', emergent[j*job_size_emergent:min(emergent.shape[0], (j+1)*job_size_emergent)],\n",
    "                             'ia', x, 'jb', dtype=int, \n",
    "                                   adjust_chunks={'a': 1, 'b': 1}).squeeze(),\n",
    "                axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3193414/2601199537.py:6: PerformanceWarning: Increasing number of chunks by factor of 18\n",
      "  da.blockwise(match, 'ijab', emergent, 'ia', x[i:min(len(dataset), i+500000)], 'jb', dtype=int,\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(dataset), \u001b[38;5;241m500000\u001b[39m):\n\u001b[1;32m      3\u001b[0m     Path(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatches/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_npy_stack\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmatches/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblockwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mijab\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memergent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mia\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m500000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                           \u001b[49m\u001b[43madjust_chunks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ma\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/om2/user/sunnyd/anaconda/envs/pythia/lib/python3.10/site-packages/dask/array/core.py:5691\u001b[0m, in \u001b[0;36mto_npy_stack\u001b[0;34m(dirname, x, axis)\u001b[0m\n\u001b[1;32m   5685\u001b[0m dsk \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   5686\u001b[0m     (name, i): (np\u001b[38;5;241m.\u001b[39msave, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dirname, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m i), key)\n\u001b[1;32m   5687\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(core\u001b[38;5;241m.\u001b[39mflatten(xx\u001b[38;5;241m.\u001b[39m__dask_keys__()))\n\u001b[1;32m   5688\u001b[0m }\n\u001b[1;32m   5690\u001b[0m graph \u001b[38;5;241m=\u001b[39m HighLevelGraph\u001b[38;5;241m.\u001b[39mfrom_collections(name, dsk, dependencies\u001b[38;5;241m=\u001b[39m[xx])\n\u001b[0;32m-> 5691\u001b[0m \u001b[43mcompute_as_if_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mArray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/om2/user/sunnyd/anaconda/envs/pythia/lib/python3.10/site-packages/dask/base.py:406\u001b[0m, in \u001b[0;36mcompute_as_if_collection\u001b[0;34m(cls, dsk, keys, scheduler, get, **kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m schedule \u001b[38;5;241m=\u001b[39m get_scheduler(scheduler\u001b[38;5;241m=\u001b[39mscheduler, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m, get\u001b[38;5;241m=\u001b[39mget)\n\u001b[1;32m    405\u001b[0m dsk2 \u001b[38;5;241m=\u001b[39m optimization_function(\u001b[38;5;28mcls\u001b[39m)(dsk, keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 406\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/om2/user/sunnyd/anaconda/envs/pythia/lib/python3.10/site-packages/distributed/client.py:3280\u001b[0m, in \u001b[0;36mClient.get\u001b[0;34m(self, dsk, keys, workers, allow_other_workers, resources, sync, asynchronous, direct, retries, priority, fifo_timeout, actors, **kwargs)\u001b[0m\n\u001b[1;32m   3278\u001b[0m         should_rejoin \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   3279\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3280\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpacked\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43masynchronous\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirect\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3281\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   3282\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m futures\u001b[38;5;241m.\u001b[39mvalues():\n",
      "File \u001b[0;32m/om2/user/sunnyd/anaconda/envs/pythia/lib/python3.10/site-packages/distributed/client.py:2383\u001b[0m, in \u001b[0;36mClient.gather\u001b[0;34m(self, futures, errors, direct, asynchronous)\u001b[0m\n\u001b[1;32m   2380\u001b[0m     local_worker \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2382\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[0;32m-> 2383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2384\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gather\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2386\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2387\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_worker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_worker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2389\u001b[0m \u001b[43m        \u001b[49m\u001b[43masynchronous\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2390\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/om2/user/sunnyd/anaconda/envs/pythia/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/om2/user/sunnyd/anaconda/envs/pythia/lib/python3.10/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "for i in np.arange(0, len(dataset), 500000):\n",
    "    Path(f\"matches/{i}\").mkdir(parents=True, exist_ok=True)\n",
    "    da.to_npy_stack(\n",
    "        f\"matches/{i}\",\n",
    "        da.blockwise(match, 'ijab', emergent, 'ia', x[i:min(len(dataset), i+500000)], 'jb', dtype=int, \n",
    "                           adjust_chunks={'a': 1, 'b': 1}).squeeze(),\n",
    "        axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out repeats\n",
    "# tokenizer.decode(x[6111].compute())\n",
    "# tokenizer.decode(x[1768].compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use tokenizer to decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "  \"EleutherAI/pythia-70m-deduped\",\n",
    "  revision=\"step3000\",\n",
    "  cache_dir=\"/om/user/sunnyd/transformers_cache\",\n",
    ")\n",
    "\n",
    "inputs = tokenizer(\"Hello, I am\", return_tensors=\"pt\")\n",
    "# tokens = model.generate(**inputs)\n",
    "# tokenizer.decode(tokens[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "1. Find a way to convert back to natural text\n",
    "2. Load data into dask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe rocking Südtribüne, a charismatic coach with his shoestring team, spearheaded by their cherubic talisman. Borussia Dortmund had well and truly shaken Bavaria, in a time where oligarchs and billionaire investors are dictating the<|endoftext|>Kim Cheong-gi\\n\\nKim Cheong-gi (born April 4, 1941) is a South Korean director of animated, fantasy, and science fiction films.\\n\\nHis work, Space Gundam V (1983), is considered one of the milestones of Korean animation of the 1980s. With actor Shim Hyung-rae, he created the Ureme series, one of the more popular Korean children\\'s series of the late 1980s.\\n\\nPartial filmography \\nRobot Taekwon V (animated) (1976)\\nRobot Taekwon V 3 (로보트 태권 V 3탄: 수중특공대) (animated) (1977)\\nGolden Wing 123 (황금날개 123) (animated) (1978)\\nRun, Wonder Princess! (날아라 원더공주) (1978)\\nTale of Three Kingdoms (삼국지) (animated) (1980)\\nSuper Taekwon V (수퍼 태권브이) (animated) (1982)\\nWuroemae from the Outside (우뢰매 = \\'Wuroemae,\\' or \\'Ureme,\\' \\'Uremae,\\' \\'Uroi-mae,\\' etc.) (외계에서 온 우뢰매) (1986)\\nSpace Gundam V (animated) (1983)\\nWuroemae from the Outside, Part II (1986)\\nOperation of Alien Uremae  (1987)\\nWuroemae 4: Thunder V Operation  (1987)\\nRobot Taekwon V and Golden Wing 123  (animated)\\nSuper Hong Gil-Dong (슈퍼 홍길동) (1987)\\nNew Machine Uremae 5 (1988)\\nGuru Kong-cho and Super Hong Kil-Dong 2 (공초도사와 슈퍼 홍길동 제2탄) (1988)\\nBioman (바이오맨) (1989)\\nThe Third Generation Uremae 6 (1989)\\nSuper Hong Kil-Dong 3 (슈퍼 홍길동 3) (1989)\\nSamtos and Daengki Ddoli (삼토스와 댕기똘이) (1990)\\nRobot Tae Kwon V 90 (로보트 태권브이 90) (1990)\\nUreme 7: The Return of Ureme Ulemae 7: Dolaon Ulemae (1992)\\nGag Unit Robot Twins (개그특공대 로봇트윈스) (1993)\\nUreme 8 (1993)\\nQueen Esther (왕후 에스더) (1996)\\nLim Keok Jeon, Korean Robin Hood (의적 임꺽정) (1997)\\nKwanggeto Taewang (The Great Emperor) (animated) (2004)\\n\\nReferences\\n\\'Hangook Manhwa\\' (한국 만화) at Korean Wikipedia\\nKim Cheong-Gi at Asiandb\\n김청기 at Yahoo! Korea (in Korean)\\n\\nExternal links\\nThe Great Emperor website\\n\\n Extensive interview can be found at www.korazy.com.au korazy.com.au\\nKim Cheong-Gi\\'s The Great Emperor at www.twitchfilm.net\\n \\xa0General information about 김청기 at the KMDb\\n\\nCategory:1941 births\\nCategory:Living people\\nCategory:South Korean film directors\\nCategory:South Korean animated film directors\\nCategory:South Korean animators<|endoftext|>Sexual orientation and suicidal behaviour in young people.\\nLesbian, gay, and bisexual (LGB) young people have been found to be at greater risk of suicidal behaviour. National prevention strategies have identified the need to reduce suicide risk in this population. However, research on specific risk factors for LGB young people that might inform suicide prevention programmes are at an early stage of development.<|endoftext|>Introduction {#Sec1}\\n============\\n\\nThe early endosome (EE) is an organelle in the endocytic pathway in filamentous fungi that is constantly moved along the microtubule (MT) by two motor proteins, kinesin and dynein^[@CR1]^. The molecular mechanisms underlying how EEs exhibit motility have been intensely investigated in the model filamentous fungi *Ustilago maydis* and *Aspergillus nidulans* ^[@CR2],[@CR3]^. The motility of filamentous fungal EEs was first visualized in *U. maydis* with Yup1, a soluble *N*-ethylmaleimide-sensitive factor attachment protein receptor (SNARE), in cells that were also stained with the endocytic marker dye FM4-64^[@CR4]^. Subsequent studies have characterized the EE-specific small GTPase Rab5 in several filamentous fungi^[@CR5]--[@CR7]^. Rab5-positive EEs move along bipolar MT arrays: movement to the plus-ends is mediated by kinesin-3, whereas that to the minus-ends is mediated by dynein, which enables long-range EE motility throughout the hyphal cell^[@CR8]^.\\n\\nBecause motor proteins driven by ATPase activity support constant EE motility, cells constitutively consume an abundance of energy. Therefore, it has been speculated that EE motility is likely to have versatile physiological roles in living cells. Analyses in *U. maydis* have revealed that EE motility supports the \"hitchhiking\" of certain molecules, such as septin mRNAs and ribosomes^[@CR9],[@CR10]^. Moreover, not only molecules but also organelles, such as peroxisomes (POs) and lipid droplets (LDs), can hitchhike via EE motility^[@CR11],[@CR12]^. Furthermore, it has been suggested that EEs can transduce pathogenic cues from the infecting hyphal tip to the nucleus^[@CR13]^. Thus, constantly moving EEs indeed have several biological roles. As a result, there might be as yet unidentified roles of EE motility in other filamentous fungi.\\n\\nRecently, Hook, a linker protein between EEs and motor proteins, has been identified together with accessory proteins FHIP and FTS in both *U. maydis* and *A. nidulans* ^[@CR14]--[@CR16]^. When Hook is deleted, EE motility is abolished and the distribution of other organelles is also impaired: for example, POs and LDs accumulate at the hyphal tip, whereas endoplasmic reticulum (ER) is partially retracted to the basal region^[@CR11]^. In *A. nidulans*, a linker protein, PxdA, that connects EEs and POs has also been identified^[@CR17]^. The apical accumulation of POs and LDs in the absence of Hook can be explained by polar drift caused by the myosin motor^[@CR18]^; however, the reason for ER retraction in the absence of EE motility is not clear. Furthermore, there are no detailed analyses of whether protein secretion is related to EE motility.\\n\\nIn this study, we have investigated the physiological roles of EE motility in *Aspergillus oryzae*, an industrially important fungus due to its property of abundant enzymatic protein secretion. By analyzing the disruptant of *Aohok1*, which encodes an ortholog of Hook, we confirmed that Δ*Aohok1* cells showed the same phenotypes of EE and PO distribution as observed in disruptants of *U. maydis* and *A. nidulans*. We further revealed that, without EE motility, formation of the apical secretory vesicle cluster Spitzenkörper was impaired, although the distributions of two other secretory organelles (ER and Golgi) were not affected. Moreover, we found that the transcript and protein levels of the *A. oryzae* major secretory protein α-amylase were significantly reduced in the absence of EE motility. Lastly, a lack of EE motility induced perturbation of conidial and sclerotial formations. Taken together, these results suggest that EE motility is crucial for abundant α-amylase production and proper cell differentiation in *A. oryzae*.\\n\\nResults {#Sec2}\\n=======\\n\\nCharacterization of *A. oryzae* EEs {#Sec3}\\n-----------------------------------\\n\\nTo visualize the motility of EEs in *A. oryzae*, we first tried to establish an EE marker protein. In other model filamentous fungi, homologs of the small GTPase Rab5, which preferentially binds to EE membrane in its GTP form, have been characterized^[@CR5]--[@CR7]^. Thus, we conducted a BLAST search using these Rab5 homologs and identified a sole Rab5 homolog in *A. oryzae*, named AoRab5 (AO090003000619; Fig.\\xa0[1A](#Fig1){ref-type=\"fig\"}). An'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(dataset[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
