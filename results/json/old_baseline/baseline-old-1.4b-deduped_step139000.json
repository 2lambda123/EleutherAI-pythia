{
  "results": {
    "crows_pairs_french_autre": {
      "likelihood_difference": 3.858173076923077,
      "likelihood_difference_stderr": 1.020440478587672,
      "pct_stereotype": 0.46153846153846156,
      "pct_stereotype_stderr": 0.14390989949130548
    },
    "crows_pairs_english_socioeconomic": {
      "likelihood_difference": 4.000164473684211,
      "likelihood_difference_stderr": 0.23645706218311846,
      "pct_stereotype": 0.6578947368421053,
      "pct_stereotype_stderr": 0.03450858738901065
    },
    "crows_pairs_french_race_color": {
      "likelihood_difference": 3.325,
      "likelihood_difference_stderr": 0.16948033696575512,
      "pct_stereotype": 0.35434782608695653,
      "pct_stereotype_stderr": 0.02232584228256916
    },
    "crows_pairs_french_age": {
      "likelihood_difference": 3.0861111111111112,
      "likelihood_difference_stderr": 0.2973493816132865,
      "pct_stereotype": 0.45555555555555555,
      "pct_stereotype_stderr": 0.05279009646630345
    },
    "crows_pairs_french_disability": {
      "likelihood_difference": 4.748579545454546,
      "likelihood_difference_stderr": 0.4737569767234526,
      "pct_stereotype": 0.5909090909090909,
      "pct_stereotype_stderr": 0.06098367211363066
    },
    "crows_pairs_english_autre": {
      "likelihood_difference": 4.244318181818182,
      "likelihood_difference_stderr": 1.5609698085757853,
      "pct_stereotype": 0.6363636363636364,
      "pct_stereotype_stderr": 0.15212000482437738
    },
    "crows_pairs_english_sexual_orientation": {
      "likelihood_difference": 4.638440860215054,
      "likelihood_difference_stderr": 0.4533146079075453,
      "pct_stereotype": 0.8494623655913979,
      "pct_stereotype_stderr": 0.03728212869390004
    },
    "crows_pairs_english_physical_appearance": {
      "likelihood_difference": 3.0364583333333335,
      "likelihood_difference_stderr": 0.29172626298410526,
      "pct_stereotype": 0.6944444444444444,
      "pct_stereotype_stderr": 0.054668187059789194
    },
    "crows_pairs_french_gender": {
      "likelihood_difference": 3.3431658878504673,
      "likelihood_difference_stderr": 0.17215316540758632,
      "pct_stereotype": 0.5109034267912772,
      "pct_stereotype_stderr": 0.02794420307081864
    },
    "crows_pairs_english_age": {
      "likelihood_difference": 3.441620879120879,
      "likelihood_difference_stderr": 0.34176193084408496,
      "pct_stereotype": 0.6153846153846154,
      "pct_stereotype_stderr": 0.05128205128205124
    },
    "crows_pairs_french_religion": {
      "likelihood_difference": 3.6244565217391305,
      "likelihood_difference_stderr": 0.40312951465977437,
      "pct_stereotype": 0.6521739130434783,
      "pct_stereotype_stderr": 0.044607754438485005
    },
    "crows_pairs_french": {
      "likelihood_difference": 3.615636180679785,
      "likelihood_difference_stderr": 0.08956685613407507,
      "pct_stereotype": 0.47584973166368516,
      "pct_stereotype_stderr": 0.01219904444151151
    },
    "crows_pairs_english_gender": {
      "likelihood_difference": 2.83876953125,
      "likelihood_difference_stderr": 0.15385491909317564,
      "pct_stereotype": 0.65,
      "pct_stereotype_stderr": 0.026705170739027836
    },
    "crows_pairs_french_socioeconomic": {
      "likelihood_difference": 3.4481026785714284,
      "likelihood_difference_stderr": 0.2689681765398075,
      "pct_stereotype": 0.5663265306122449,
      "pct_stereotype_stderr": 0.035489311596949215
    },
    "crows_pairs_english_nationality": {
      "likelihood_difference": 3.3557581018518516,
      "likelihood_difference_stderr": 0.23430254346210275,
      "pct_stereotype": 0.5185185185185185,
      "pct_stereotype_stderr": 0.03407632093854051
    },
    "crows_pairs_english": {
      "likelihood_difference": 3.478831246273107,
      "likelihood_difference_stderr": 0.08322929550382462,
      "pct_stereotype": 0.616577221228384,
      "pct_stereotype_stderr": 0.011876697253175876
    },
    "crows_pairs_french_physical_appearance": {
      "likelihood_difference": 3.9526909722222223,
      "likelihood_difference_stderr": 0.5247261334016575,
      "pct_stereotype": 0.6805555555555556,
      "pct_stereotype_stderr": 0.05533504751887217
    },
    "crows_pairs_english_religion": {
      "likelihood_difference": 3.3671171171171173,
      "likelihood_difference_stderr": 0.3198184477561958,
      "pct_stereotype": 0.7297297297297297,
      "pct_stereotype_stderr": 0.042343213610845386
    },
    "crows_pairs_french_nationality": {
      "likelihood_difference": 4.395133399209486,
      "likelihood_difference_stderr": 0.25331653453725606,
      "pct_stereotype": 0.31225296442687744,
      "pct_stereotype_stderr": 0.029192237133579074
    },
    "crows_pairs_english_disability": {
      "likelihood_difference": 5.546153846153846,
      "likelihood_difference_stderr": 0.5375340247418553,
      "pct_stereotype": 0.7230769230769231,
      "pct_stereotype_stderr": 0.05593476758557301
    },
    "crows_pairs_english_race_color": {
      "likelihood_difference": 3.3397514763779528,
      "likelihood_difference_stderr": 0.15271361344684964,
      "pct_stereotype": 0.5295275590551181,
      "pct_stereotype_stderr": 0.022167024359332235
    },
    "crows_pairs_french_sexual_orientation": {
      "likelihood_difference": 3.629120879120879,
      "likelihood_difference_stderr": 0.3259419057927512,
      "pct_stereotype": 0.7802197802197802,
      "pct_stereotype_stderr": 0.04364972632898534
    }
  },
  "versions": {
    "crows_pairs_french_autre": 0,
    "crows_pairs_english_socioeconomic": 0,
    "crows_pairs_french_race_color": 0,
    "crows_pairs_french_age": 0,
    "crows_pairs_french_disability": 0,
    "crows_pairs_english_autre": 0,
    "crows_pairs_english_sexual_orientation": 0,
    "crows_pairs_english_physical_appearance": 0,
    "crows_pairs_french_gender": 0,
    "crows_pairs_english_age": 0,
    "crows_pairs_french_religion": 0,
    "crows_pairs_french": 0,
    "crows_pairs_english_gender": 0,
    "crows_pairs_french_socioeconomic": 0,
    "crows_pairs_english_nationality": 0,
    "crows_pairs_english": 0,
    "crows_pairs_french_physical_appearance": 0,
    "crows_pairs_english_religion": 0,
    "crows_pairs_french_nationality": 0,
    "crows_pairs_english_disability": 0,
    "crows_pairs_english_race_color": 0,
    "crows_pairs_french_sexual_orientation": 0
  },
  "config": {
    "model": "hf-causal",
    "model_args": "pretrained=EleutherAI/pythia-1.4b-deduped,revision=step139000",
    "num_fewshot": 0,
    "batch_size": 4,
    "device": "cuda:3",
    "no_cache": true,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}