{
  "results": {
    "crows_pairs_french_autre": {
      "likelihood_difference": 2.5408653846153846,
      "likelihood_difference_stderr": 0.6779215529125424,
      "pct_stereotype": 0.6153846153846154,
      "pct_stereotype_stderr": 0.14044168141158106
    },
    "crows_pairs_french_physical_appearance": {
      "likelihood_difference": 3.404513888888889,
      "likelihood_difference_stderr": 0.4397798616955487,
      "pct_stereotype": 0.6388888888888888,
      "pct_stereotype_stderr": 0.0570038146170086
    },
    "crows_pairs_english_sexual_orientation": {
      "likelihood_difference": 4.455645161290323,
      "likelihood_difference_stderr": 0.44812989679253673,
      "pct_stereotype": 0.8387096774193549,
      "pct_stereotype_stderr": 0.03834564688497144
    },
    "crows_pairs_french_disability": {
      "likelihood_difference": 4.975378787878788,
      "likelihood_difference_stderr": 0.4776255280895497,
      "pct_stereotype": 0.6515151515151515,
      "pct_stereotype_stderr": 0.0591013677911929
    },
    "crows_pairs_french_gender": {
      "likelihood_difference": 3.587081386292835,
      "likelihood_difference_stderr": 0.18478332921258395,
      "pct_stereotype": 0.5202492211838006,
      "pct_stereotype_stderr": 0.027927918885132307
    },
    "crows_pairs_english_autre": {
      "likelihood_difference": 4.5397727272727275,
      "likelihood_difference_stderr": 1.7292863561749663,
      "pct_stereotype": 0.7272727272727273,
      "pct_stereotype_stderr": 0.14083575804390605
    },
    "crows_pairs_french_socioeconomic": {
      "likelihood_difference": 3.789859693877551,
      "likelihood_difference_stderr": 0.26767503360180106,
      "pct_stereotype": 0.7142857142857143,
      "pct_stereotype_stderr": 0.03235077240413132
    },
    "crows_pairs_french_sexual_orientation": {
      "likelihood_difference": 3.342032967032967,
      "likelihood_difference_stderr": 0.3000183473024323,
      "pct_stereotype": 0.6923076923076923,
      "pct_stereotype_stderr": 0.04865042554105198
    },
    "crows_pairs_french_race_color": {
      "likelihood_difference": 3.363654891304348,
      "likelihood_difference_stderr": 0.18825229028527968,
      "pct_stereotype": 0.4217391304347826,
      "pct_stereotype_stderr": 0.023050349185909674
    },
    "crows_pairs_english_nationality": {
      "likelihood_difference": 3.697410300925926,
      "likelihood_difference_stderr": 0.25632355533053297,
      "pct_stereotype": 0.5740740740740741,
      "pct_stereotype_stderr": 0.033723432716530624
    },
    "crows_pairs_english_race_color": {
      "likelihood_difference": 3.5812623031496065,
      "likelihood_difference_stderr": 0.15446199959940712,
      "pct_stereotype": 0.5551181102362205,
      "pct_stereotype_stderr": 0.022070444592370703
    },
    "crows_pairs_english_age": {
      "likelihood_difference": 3.8049450549450547,
      "likelihood_difference_stderr": 0.36338248751338215,
      "pct_stereotype": 0.6153846153846154,
      "pct_stereotype_stderr": 0.05128205128205124
    },
    "crows_pairs_english_religion": {
      "likelihood_difference": 3.775760135135135,
      "likelihood_difference_stderr": 0.3471386453159655,
      "pct_stereotype": 0.7927927927927928,
      "pct_stereotype_stderr": 0.03864434340455356
    },
    "crows_pairs_english_disability": {
      "likelihood_difference": 5.571634615384616,
      "likelihood_difference_stderr": 0.5812212933119247,
      "pct_stereotype": 0.7230769230769231,
      "pct_stereotype_stderr": 0.055934767585573
    },
    "crows_pairs_french": {
      "likelihood_difference": 3.6107912194394753,
      "likelihood_difference_stderr": 0.0883475537145696,
      "pct_stereotype": 0.5223613595706619,
      "pct_stereotype_stderr": 0.012201079063310664
    },
    "crows_pairs_french_age": {
      "likelihood_difference": 2.8118055555555554,
      "likelihood_difference_stderr": 0.28667944640362675,
      "pct_stereotype": 0.4888888888888889,
      "pct_stereotype_stderr": 0.05298680599073449
    },
    "crows_pairs_french_religion": {
      "likelihood_difference": 3.838315217391304,
      "likelihood_difference_stderr": 0.319968734335705,
      "pct_stereotype": 0.6956521739130435,
      "pct_stereotype_stderr": 0.043095185024639285
    },
    "crows_pairs_english_gender": {
      "likelihood_difference": 4.246630859375,
      "likelihood_difference_stderr": 0.20724884850464445,
      "pct_stereotype": 0.634375,
      "pct_stereotype_stderr": 0.026964702306061943
    },
    "crows_pairs_english_physical_appearance": {
      "likelihood_difference": 3.7374131944444446,
      "likelihood_difference_stderr": 0.35646812667678496,
      "pct_stereotype": 0.7361111111111112,
      "pct_stereotype_stderr": 0.052306187285139825
    },
    "crows_pairs_english_socioeconomic": {
      "likelihood_difference": 4.212993421052632,
      "likelihood_difference_stderr": 0.24573896258276273,
      "pct_stereotype": 0.6894736842105263,
      "pct_stereotype_stderr": 0.03365713545671698
    },
    "crows_pairs_english": {
      "likelihood_difference": 3.9583985539654143,
      "likelihood_difference_stderr": 0.08993848273117225,
      "pct_stereotype": 0.6380441264162194,
      "pct_stereotype_stderr": 0.011738596232291112
    },
    "crows_pairs_french_nationality": {
      "likelihood_difference": 3.9866600790513833,
      "likelihood_difference_stderr": 0.22233663923772898,
      "pct_stereotype": 0.35968379446640314,
      "pct_stereotype_stderr": 0.030231340989680604
    }
  },
  "versions": {
    "crows_pairs_french_autre": 0,
    "crows_pairs_french_physical_appearance": 0,
    "crows_pairs_english_sexual_orientation": 0,
    "crows_pairs_french_disability": 0,
    "crows_pairs_french_gender": 0,
    "crows_pairs_english_autre": 0,
    "crows_pairs_french_socioeconomic": 0,
    "crows_pairs_french_sexual_orientation": 0,
    "crows_pairs_french_race_color": 0,
    "crows_pairs_english_nationality": 0,
    "crows_pairs_english_race_color": 0,
    "crows_pairs_english_age": 0,
    "crows_pairs_english_religion": 0,
    "crows_pairs_english_disability": 0,
    "crows_pairs_french": 0,
    "crows_pairs_french_age": 0,
    "crows_pairs_french_religion": 0,
    "crows_pairs_english_gender": 0,
    "crows_pairs_english_physical_appearance": 0,
    "crows_pairs_english_socioeconomic": 0,
    "crows_pairs_english": 0,
    "crows_pairs_french_nationality": 0
  },
  "config": {
    "model": "hf-causal",
    "model_args": "use_accelerate=True,pretrained=EleutherAI/pythia-6.9b-deduped,revision=step137000",
    "num_fewshot": 0,
    "batch_size": 2,
    "device": null,
    "no_cache": true,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}