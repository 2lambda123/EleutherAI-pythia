{
  "results": {
    "crows_pairs_english_physical_appearance": {
      "likelihood_difference": 2.931423611111111,
      "likelihood_difference_stderr": 0.27797582786515856,
      "pct_stereotype": 0.6666666666666666,
      "pct_stereotype_stderr": 0.055945423886445925
    },
    "crows_pairs_french_physical_appearance": {
      "likelihood_difference": 3.834201388888889,
      "likelihood_difference_stderr": 0.5113633038668688,
      "pct_stereotype": 0.6527777777777778,
      "pct_stereotype_stderr": 0.05650114676852965
    },
    "crows_pairs_english_sexual_orientation": {
      "likelihood_difference": 4.655241935483871,
      "likelihood_difference_stderr": 0.4707308862806399,
      "pct_stereotype": 0.8387096774193549,
      "pct_stereotype_stderr": 0.03834564688497144
    },
    "crows_pairs_french_gender": {
      "likelihood_difference": 3.4328271028037385,
      "likelihood_difference_stderr": 0.17451832527833766,
      "pct_stereotype": 0.5109034267912772,
      "pct_stereotype_stderr": 0.027944203070818643
    },
    "crows_pairs_french": {
      "likelihood_difference": 3.5948587507453786,
      "likelihood_difference_stderr": 0.08982900422530198,
      "pct_stereotype": 0.46153846153846156,
      "pct_stereotype_stderr": 0.012177111585868346
    },
    "crows_pairs_french_disability": {
      "likelihood_difference": 4.406723484848484,
      "likelihood_difference_stderr": 0.49355111125495593,
      "pct_stereotype": 0.5606060606060606,
      "pct_stereotype_stderr": 0.06156009014560979
    },
    "crows_pairs_french_age": {
      "likelihood_difference": 2.8934027777777778,
      "likelihood_difference_stderr": 0.28646286361945655,
      "pct_stereotype": 0.5,
      "pct_stereotype_stderr": 0.052999894000318
    },
    "crows_pairs_english": {
      "likelihood_difference": 3.415427474657126,
      "likelihood_difference_stderr": 0.08375633412198717,
      "pct_stereotype": 0.6082289803220036,
      "pct_stereotype_stderr": 0.011923745582753312
    },
    "crows_pairs_english_disability": {
      "likelihood_difference": 5.591826923076923,
      "likelihood_difference_stderr": 0.5273612786096218,
      "pct_stereotype": 0.7384615384615385,
      "pct_stereotype_stderr": 0.05493406483494501
    },
    "crows_pairs_english_nationality": {
      "likelihood_difference": 3.2845775462962963,
      "likelihood_difference_stderr": 0.23383913362682587,
      "pct_stereotype": 0.5138888888888888,
      "pct_stereotype_stderr": 0.03408655867977749
    },
    "crows_pairs_french_sexual_orientation": {
      "likelihood_difference": 3.2884615384615383,
      "likelihood_difference_stderr": 0.34302011983077035,
      "pct_stereotype": 0.6703296703296703,
      "pct_stereotype_stderr": 0.04955219508596585
    },
    "crows_pairs_french_autre": {
      "likelihood_difference": 3.6971153846153846,
      "likelihood_difference_stderr": 1.0482726308102854,
      "pct_stereotype": 0.46153846153846156,
      "pct_stereotype_stderr": 0.14390989949130548
    },
    "crows_pairs_english_religion": {
      "likelihood_difference": 3.409065315315315,
      "likelihood_difference_stderr": 0.3223085844733619,
      "pct_stereotype": 0.7567567567567568,
      "pct_stereotype_stderr": 0.04090743073860916
    },
    "crows_pairs_english_socioeconomic": {
      "likelihood_difference": 3.7088815789473686,
      "likelihood_difference_stderr": 0.23655204398390578,
      "pct_stereotype": 0.6210526315789474,
      "pct_stereotype_stderr": 0.03528765094094842
    },
    "crows_pairs_english_autre": {
      "likelihood_difference": 4.107954545454546,
      "likelihood_difference_stderr": 1.5909420654050248,
      "pct_stereotype": 0.7272727272727273,
      "pct_stereotype_stderr": 0.14083575804390605
    },
    "crows_pairs_english_race_color": {
      "likelihood_difference": 3.369402066929134,
      "likelihood_difference_stderr": 0.15544092907795518,
      "pct_stereotype": 0.531496062992126,
      "pct_stereotype_stderr": 0.022161679438492773
    },
    "crows_pairs_english_gender": {
      "likelihood_difference": 2.698291015625,
      "likelihood_difference_stderr": 0.15077350585477203,
      "pct_stereotype": 0.61875,
      "pct_stereotype_stderr": 0.027193630402775476
    },
    "crows_pairs_french_nationality": {
      "likelihood_difference": 4.457386363636363,
      "likelihood_difference_stderr": 0.25358687428853416,
      "pct_stereotype": 0.308300395256917,
      "pct_stereotype_stderr": 0.029090121430592312
    },
    "crows_pairs_french_socioeconomic": {
      "likelihood_difference": 3.3986766581632653,
      "likelihood_difference_stderr": 0.27280429077307955,
      "pct_stereotype": 0.5663265306122449,
      "pct_stereotype_stderr": 0.035489311596949215
    },
    "crows_pairs_french_religion": {
      "likelihood_difference": 3.729619565217391,
      "likelihood_difference_stderr": 0.38684725391038705,
      "pct_stereotype": 0.6869565217391305,
      "pct_stereotype_stderr": 0.04343247016610823
    },
    "crows_pairs_english_age": {
      "likelihood_difference": 3.3774038461538463,
      "likelihood_difference_stderr": 0.3443590005683373,
      "pct_stereotype": 0.6263736263736264,
      "pct_stereotype_stderr": 0.050993431663867696
    },
    "crows_pairs_french_race_color": {
      "likelihood_difference": 3.3244565217391306,
      "likelihood_difference_stderr": 0.17039645999321784,
      "pct_stereotype": 0.3173913043478261,
      "pct_stereotype_stderr": 0.02172586504427457
    }
  },
  "versions": {
    "crows_pairs_english_physical_appearance": 0,
    "crows_pairs_french_physical_appearance": 0,
    "crows_pairs_english_sexual_orientation": 0,
    "crows_pairs_french_gender": 0,
    "crows_pairs_french": 0,
    "crows_pairs_french_disability": 0,
    "crows_pairs_french_age": 0,
    "crows_pairs_english": 0,
    "crows_pairs_english_disability": 0,
    "crows_pairs_english_nationality": 0,
    "crows_pairs_french_sexual_orientation": 0,
    "crows_pairs_french_autre": 0,
    "crows_pairs_english_religion": 0,
    "crows_pairs_english_socioeconomic": 0,
    "crows_pairs_english_autre": 0,
    "crows_pairs_english_race_color": 0,
    "crows_pairs_english_gender": 0,
    "crows_pairs_french_nationality": 0,
    "crows_pairs_french_socioeconomic": 0,
    "crows_pairs_french_religion": 0,
    "crows_pairs_english_age": 0,
    "crows_pairs_french_race_color": 0
  },
  "config": {
    "model": "hf-causal",
    "model_args": "pretrained=EleutherAI/pythia-1.4b-deduped,revision=step115000",
    "num_fewshot": 0,
    "batch_size": 4,
    "device": "cuda:3",
    "no_cache": true,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}