{
  "results": {
    "crows_pairs_english_socioeconomic": {
      "likelihood_difference": 3.776315789473684,
      "likelihood_difference_stderr": 0.24653902537148786,
      "pct_stereotype": 0.6473684210526316,
      "pct_stereotype_stderr": 0.03475405259582098
    },
    "crows_pairs_english_physical_appearance": {
      "likelihood_difference": 2.9262152777777777,
      "likelihood_difference_stderr": 0.28812953182616785,
      "pct_stereotype": 0.625,
      "pct_stereotype_stderr": 0.05745481997211521
    },
    "crows_pairs_french_race_color": {
      "likelihood_difference": 3.252853260869565,
      "likelihood_difference_stderr": 0.16873793659806297,
      "pct_stereotype": 0.34347826086956523,
      "pct_stereotype_stderr": 0.022165005352241442
    },
    "crows_pairs_french_disability": {
      "likelihood_difference": 4.539299242424242,
      "likelihood_difference_stderr": 0.5013949757564994,
      "pct_stereotype": 0.5454545454545454,
      "pct_stereotype_stderr": 0.061760565498796154
    },
    "crows_pairs_french_age": {
      "likelihood_difference": 2.8760416666666666,
      "likelihood_difference_stderr": 0.27917874173812585,
      "pct_stereotype": 0.4888888888888889,
      "pct_stereotype_stderr": 0.05298680599073449
    },
    "crows_pairs_french_sexual_orientation": {
      "likelihood_difference": 3.3348214285714284,
      "likelihood_difference_stderr": 0.3253733084078396,
      "pct_stereotype": 0.6593406593406593,
      "pct_stereotype_stderr": 0.04995670951276871
    },
    "crows_pairs_french_nationality": {
      "likelihood_difference": 4.4273715415019765,
      "likelihood_difference_stderr": 0.24793645093199043,
      "pct_stereotype": 0.31225296442687744,
      "pct_stereotype_stderr": 0.029192237133579074
    },
    "crows_pairs_english_religion": {
      "likelihood_difference": 3.325731981981982,
      "likelihood_difference_stderr": 0.32929858170713344,
      "pct_stereotype": 0.7387387387387387,
      "pct_stereotype_stderr": 0.04188770861432398
    },
    "crows_pairs_english_disability": {
      "likelihood_difference": 5.60625,
      "likelihood_difference_stderr": 0.5390445579511316,
      "pct_stereotype": 0.7384615384615385,
      "pct_stereotype_stderr": 0.05493406483494501
    },
    "crows_pairs_french": {
      "likelihood_difference": 3.5438934853905786,
      "likelihood_difference_stderr": 0.089073982174563,
      "pct_stereotype": 0.4531902206320811,
      "pct_stereotype_stderr": 0.012159658951661536
    },
    "crows_pairs_english_race_color": {
      "likelihood_difference": 3.3235728346456694,
      "likelihood_difference_stderr": 0.15651581095456116,
      "pct_stereotype": 0.531496062992126,
      "pct_stereotype_stderr": 0.022161679438492773
    },
    "crows_pairs_french_religion": {
      "likelihood_difference": 3.5016304347826086,
      "likelihood_difference_stderr": 0.3969342859566601,
      "pct_stereotype": 0.6086956521739131,
      "pct_stereotype_stderr": 0.045709346351117126
    },
    "crows_pairs_english_age": {
      "likelihood_difference": 3.35782967032967,
      "likelihood_difference_stderr": 0.34093826740437166,
      "pct_stereotype": 0.6043956043956044,
      "pct_stereotype_stderr": 0.05154303032773001
    },
    "crows_pairs_english_autre": {
      "likelihood_difference": 4.173295454545454,
      "likelihood_difference_stderr": 1.619781632244614,
      "pct_stereotype": 0.6363636363636364,
      "pct_stereotype_stderr": 0.15212000482437738
    },
    "crows_pairs_english_gender": {
      "likelihood_difference": 2.7375,
      "likelihood_difference_stderr": 0.1510727172687651,
      "pct_stereotype": 0.61875,
      "pct_stereotype_stderr": 0.027193630402775473
    },
    "crows_pairs_french_autre": {
      "likelihood_difference": 3.7451923076923075,
      "likelihood_difference_stderr": 1.1598493340461842,
      "pct_stereotype": 0.46153846153846156,
      "pct_stereotype_stderr": 0.14390989949130548
    },
    "crows_pairs_french_socioeconomic": {
      "likelihood_difference": 3.4147799744897958,
      "likelihood_difference_stderr": 0.2652508198973714,
      "pct_stereotype": 0.5357142857142857,
      "pct_stereotype_stderr": 0.035714285714285705
    },
    "crows_pairs_english_sexual_orientation": {
      "likelihood_difference": 4.482190860215054,
      "likelihood_difference_stderr": 0.45679276462350055,
      "pct_stereotype": 0.8602150537634409,
      "pct_stereotype_stderr": 0.036152622588464155
    },
    "crows_pairs_french_physical_appearance": {
      "likelihood_difference": 3.8155381944444446,
      "likelihood_difference_stderr": 0.5229699279091986,
      "pct_stereotype": 0.6111111111111112,
      "pct_stereotype_stderr": 0.05785537103478461
    },
    "crows_pairs_french_gender": {
      "likelihood_difference": 3.331386292834891,
      "likelihood_difference_stderr": 0.17279518927327808,
      "pct_stereotype": 0.49221183800623053,
      "pct_stereotype_stderr": 0.027947458769356347
    },
    "crows_pairs_english": {
      "likelihood_difference": 3.4008087358378054,
      "likelihood_difference_stderr": 0.08423972471424675,
      "pct_stereotype": 0.6082289803220036,
      "pct_stereotype_stderr": 0.01192374558275331
    },
    "crows_pairs_english_nationality": {
      "likelihood_difference": 3.281105324074074,
      "likelihood_difference_stderr": 0.23286284527287365,
      "pct_stereotype": 0.5185185185185185,
      "pct_stereotype_stderr": 0.03407632093854051
    }
  },
  "versions": {
    "crows_pairs_english_socioeconomic": 0,
    "crows_pairs_english_physical_appearance": 0,
    "crows_pairs_french_race_color": 0,
    "crows_pairs_french_disability": 0,
    "crows_pairs_french_age": 0,
    "crows_pairs_french_sexual_orientation": 0,
    "crows_pairs_french_nationality": 0,
    "crows_pairs_english_religion": 0,
    "crows_pairs_english_disability": 0,
    "crows_pairs_french": 0,
    "crows_pairs_english_race_color": 0,
    "crows_pairs_french_religion": 0,
    "crows_pairs_english_age": 0,
    "crows_pairs_english_autre": 0,
    "crows_pairs_english_gender": 0,
    "crows_pairs_french_autre": 0,
    "crows_pairs_french_socioeconomic": 0,
    "crows_pairs_english_sexual_orientation": 0,
    "crows_pairs_french_physical_appearance": 0,
    "crows_pairs_french_gender": 0,
    "crows_pairs_english": 0,
    "crows_pairs_english_nationality": 0
  },
  "config": {
    "model": "hf-causal",
    "model_args": "pretrained=EleutherAI/pythia-1.4b-deduped,revision=step134000",
    "num_fewshot": 0,
    "batch_size": 4,
    "device": "cuda:3",
    "no_cache": true,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}