train/lm_loss	step
2.2237446308135986	53001
2.2540717124938965	53002
2.2988266944885254	53003
2.260072708129883	53004
2.292724370956421	53005
2.2542166709899902	53006
2.2965927124023438	53007
2.23175311088562	53008
2.247994899749756	53009
2.2661006450653076	53010
2.286404848098755	53011
2.252528667449951	53012
2.2447144985198975	53013
2.2396984100341797	53014
2.2717790603637695	53015
2.272275924682617	53016
2.2718944549560547	53017
2.2879183292388916	53018
2.248337745666504	53019
2.270730495452881	53020
2.307792901992798	53021
2.2316911220550537	53022
2.261956214904785	53023
2.2820968627929688	53024
2.310218572616577	53025
2.277512788772583	53026
2.284914970397949	53027
2.2394957542419434	53028
2.254753351211548	53029
2.270465850830078	53030
2.2432804107666016	53031
2.2443814277648926	53032
2.2469935417175293	53033
2.2650551795959473	53034
2.256209135055542	53035
2.2360470294952393	53036
2.288651943206787	53037
2.258493185043335	53038
